{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#B40431>Ensemble Methods<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#424242>A Sexy Machine Learning Strategy<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to assess the credit risk of someone using its finantial history. \n",
    "Basically, we'll use 20 finantial attributes to classify people as good or bad credit risks. \n",
    "\n",
    "We have a set of samples labeled as low risk or high risk. So, this is a binary classification problem.\n",
    "\n",
    "Attributes:\n",
    "-  __A1:__ status of existing checking account (categorical)\n",
    "-  __A2:__ credit duration in months (numerical)\n",
    "-  __A3:__ credit history (categorical)\n",
    "-  __A4:__ credit purpose (categorical)\n",
    "-  __A5:__ credit amount (numerical)\n",
    "-  __A6:__ savings account/bonds (categorical)\n",
    "-  __A7:__ how long one is employed in the current job (categorical)\n",
    "-  __A8:__ installment rate in percentage of disposable income (numerical)\n",
    "-  __A9:__ personal status and sex (categorical)\n",
    "-  __A10:__ other debtors/guarantors (categorical)\n",
    "-  __A11:__ how long one lives in the current residence (numerical)\n",
    "-  __A12:__ property (categorical)\n",
    "-  __A13:__ age (numerical)\n",
    "-  __A14:__ other installment plans (categorical)\n",
    "-  __A15:__ housing (categorical)\n",
    "-  __A16:__ number of existing credits at this bank (numerical)\n",
    "-  __A17:__ job (categorical)\n",
    "-  __A18:__ number of people being liable to provide maintenance for (numerical) \n",
    "-  __A19:__ telephone (categorical, bool)\n",
    "-  __A20:__ foreign worker (categorical, bool)\n",
    "\n",
    "The dataset is available online:\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# seeding the generated number makes our results reproducible\n",
    "from random import seed \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_curve, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory and paths\n",
    "project_dir = os.path.dirname(os.getcwd())\n",
    "path_data = os.path.join(project_dir, 'data', 'german_data.txt')\n",
    "\n",
    "settings = {'grid_search':False}\n",
    "seed(1994)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "column_name = ['A'+str(i) for i in range(1,21)] + ['TARGET']\n",
    "df_data = pd.read_csv(path_data, sep=\" \", header=None, names=column_name, dtype={'TARGET':str})\n",
    "\n",
    "# replace class names\n",
    "df_data.replace({'TARGET':{'1':'good', '2':'bad'}}, inplace=True)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Use the Scikit-learn flowchart to find one reliable estimator for the job\n",
    "https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - check how many samples you have\n",
    "print('Number of samples: {}'.format(df_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - check if classes are balanced or unbalanced\n",
    "data = df_data.TARGET.value_counts()\n",
    "#sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set()\n",
    "sns.barplot(x = data.index, y=data.values, palette=\"Blues_d\", order=['good', 'bad'])\n",
    "plt.title('Classes Distribution')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: Classes are unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - check a numerical feature - credit duration in month\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set()\n",
    "sns.boxplot(x=\"TARGET\", y=\"A2\", data=df_data, palette=\"Blues_d\", whis=10)\n",
    "plt.title('Credit Duration')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Duration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 - check a category feature - status of existing checking accounts\n",
    "data = pd.DataFrame(df_data.groupby('TARGET').apply(lambda x: x['A1'].value_counts()))\n",
    "data.reset_index(inplace=True)\n",
    "data.columns=['TARGET', 'A1', 'COUNT']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set()\n",
    "sns.barplot(x='A1', y='COUNT', hue='TARGET', data=data, palette=\"Blues_d\", hue_order=['good', 'bad'], \n",
    "            order=sorted(data.A1.unique()))\n",
    "plt.title('Checking Accounts')\n",
    "plt.xlabel('Status of Existing Checking Accounts')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  __A11:__ 0 DM\n",
    "-  __A12:__ < 200 DM\n",
    "-  __A13:__ >= 200 DM\n",
    "-  __A14:__ no checking account\n",
    "\n",
    "*DM stands for Deutsche Mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 - check a category feature - credit history\n",
    "data = pd.DataFrame(data=df_data.groupby('TARGET')['A3'].value_counts())\n",
    "data.columns = ['COUNT']\n",
    "data.reset_index(inplace=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set()\n",
    "sns.barplot(x='A3', y='COUNT', hue='TARGET', data=data, palette=\"Blues_d\", hue_order=['good', 'bad'], \n",
    "            order=sorted(data.A3.unique()))\n",
    "plt.title('Credit History')\n",
    "plt.xlabel('Credit history')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  __A30:__ No credit taken/ all credits paid back duly\n",
    "-  __A31:__ All credits at this bank paid back duly\n",
    "-  __A32:__ Existing credits paid back duly till now\n",
    "-  __A33:__ Delay in paying off in the past\n",
    "-  __A34:__ Critical account/ other credits existing at different banks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#B40431>__Exercise 1:__<font> \n",
    "-  Generate the bar chart for attribute __A17__, grouped by class. \n",
    "-  Draw conclusions from the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a category feature - job qualification\n",
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  __A171:__ unemployed or unskilled - non-residen\n",
    "-  __A172:__ unskilled - resident\n",
    "-  __A173:__ skilled employee or official\n",
    "-  __A174:__ management, self-employed, highly qualified employee or officer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert categorical features into dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictors and classes\n",
    "inputs = df_data.iloc[:,:-1]\n",
    "targets = df_data['TARGET']\n",
    "\n",
    "# Convert categorical variable into dummy/indicator variables\n",
    "categ_cols = ['A1', 'A3', 'A4', 'A6', 'A7', 'A9', 'A10', 'A12', 'A14', 'A15', 'A17', 'A19', 'A20']\n",
    "inputs = pd.get_dummies(inputs, columns=categ_cols, drop_first=True)\n",
    "inputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into random train and test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.3, stratify=targets, random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#B40431>Random Forest<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters \n",
    "params_grid = {\n",
    "    'n_estimators': [10, 100, 1000, 5000],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "    'max_features': ['auto'],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exhaustive search over specified parameter values for an estimator\n",
    "if settings['grid_search']:\n",
    "    clf_srch_rf = GridSearchCV(RandomForestClassifier(), params_grid, scoring='roc_auc', cv=3)\n",
    "    clf_srch_rf.fit(X_train, y_train)\n",
    "\n",
    "    # Get best parameters\n",
    "    params = clf_srch_rf.best_params_\n",
    "else:\n",
    "    # If you want to avoid performing the grid search, uncomment the code below\n",
    "    params = {\n",
    "        'bootstrap': True, \n",
    "        'criterion': 'gini',\n",
    "        'max_depth': None,\n",
    "        'max_features': 'auto',\n",
    "        'min_samples_leaf': 1,\n",
    "        'min_samples_split': 2,\n",
    "        'n_estimators': 1000}\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a forest of trees from the training set (X_train, y_train)\n",
    "clf_rf = RandomForestClassifier(**params)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict class for X_train and X_test\n",
    "y_pred_train = clf_rf.predict(X_train)\n",
    "y_pred_test = clf_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "TPR = Recall = \\frac{TP}{P} = \\frac{TP}{TP+FN}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "FPR = Fall-out = \\frac{FP}{N} = \\frac{FP}{FP+TN}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "PPV = Precision = \\frac{TP}{TP+FP}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "f1 = 2\\frac{PPV*TPR}{PPV+TPV}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix to evaluate the accuracy of a classification\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test, labels=['good', 'bad'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set()\n",
    "sns.heatmap(conf_matrix, xticklabels=['good', 'bad'], yticklabels=['good', 'bad'], annot=True, cmap=\"Blues\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The label \"bad\" is considered as positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('True Negative (TN): {}'.format(conf_matrix[0,0]))\n",
    "print('False Positive (FP): {}'.format(conf_matrix[0,1]))\n",
    "print('False Negative (FN): {}'.format(conf_matrix[1,0]))\n",
    "print('True Negative (TN): {}'.format(conf_matrix[1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classification report\n",
    "df_class_report = pd.DataFrame(classification_report(y_test, y_pred_test, output_dict=True))\n",
    "print(df_class_report)\n",
    "\n",
    "# Get accuracy score\n",
    "acc = accuracy_score(y_test, y_pred_test)\n",
    "print('\\nAccuracy = {:.2%}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(y, target='bad'):\n",
    "    return [1 if y_i=='bad' else 0 for y_i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve \n",
    "y_pred_test_prob = clf_rf.predict_proba(X_test)\n",
    "fpr, tpr, trs = roc_curve(binarize(y_test), y_pred_test_prob[:,0])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set()\n",
    "sns.lineplot(fpr, tpr, palette=\"Blues_d\")\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.show()\n",
    "\n",
    "print('AUC: {:.2}'.format(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#B40431>__Exercise 2:__<font> \n",
    "-  Check for overfitting by computing the accuracy score both for training set and test set.\n",
    "-  As you know, RF has some knobs to avoid overfitting. Apply some changes to such parameters and draw some conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for overfitting\n",
    "# if accuracy score for the training set is much higher than the accuracy for the test set, \n",
    "# the model is prone to overfitting\n",
    "\n",
    "# training set\n",
    "# insert your code here\n",
    "\n",
    "# test set\n",
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#B40431>__Exercise 3:__<font> \n",
    "-  Check the feature importance. Find out which are the 5 attributes with higher importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the feature importances \n",
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#B40431>Gradient Boosting Machine<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#B40431>__Exercise 4:__<font> \n",
    "-  Fit a Gradient Boosting Machine to the German Credit Risk Assessment dataset.\n",
    "-  Evaluate the model performance.\n",
    "-  Check which model performs better in this case and try to understand why.\n",
    "    \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters \n",
    "params_grid = {\n",
    "    'loss': ['deviance', 'exponential'],\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [10, 100, 1000, 5000],\n",
    "    'criterion': ['friedman_mse'],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "    'max_features': ['auto'],\n",
    "    'subsample': [0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exhaustive search over specified parameter values for an estimator\n",
    "if settings['grid_search']:\n",
    "    # insert your code here\n",
    "    pass\n",
    "else:\n",
    "    # If you want to avoid performing the grid search, uncomment the code below\n",
    "    params = {\n",
    "        'criterion': 'friedman_mse',\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 30,\n",
    "        'max_features': 'auto',\n",
    "        'min_samples_leaf': 5,\n",
    "        'min_samples_split': 10,\n",
    "        'n_estimators': 350,\n",
    "        'subsample': .6\n",
    "        }\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a forest of trees from the training set (X_train, y_train)\n",
    "# insert your code here\n",
    "\n",
    "# Predict class for X_train and X_test\n",
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix to evaluate the accuracy of a classification\n",
    "# insert your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print TN, FP, FN and TN\n",
    "# insert your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classification report\n",
    "# insert your code here\n",
    "\n",
    "# Get accuracy score\n",
    "# insert your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve \n",
    "# insert your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for overfitting\n",
    "# if accuracy score for the training set is much higher than the accuracy for the test set, \n",
    "# the model is prone to overfitting\n",
    "\n",
    "# training set\n",
    "# insert your code here\n",
    "\n",
    "# test set\n",
    "# insert your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the feature importances\n",
    "# insert your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
